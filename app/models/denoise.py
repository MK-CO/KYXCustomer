"""
å»å™ªè®°å½•æ•°æ®æ¨¡å‹
ç”¨äºç®¡ç†å†…å®¹å»å™ªå¤„ç†çš„è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯
"""
import json
import logging
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any
from sqlalchemy import text
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


def safe_json_dumps(obj: Any, ensure_ascii: bool = False) -> str:
    """
    å®‰å…¨çš„JSONåºåˆ—åŒ–å‡½æ•°ï¼Œå¤„ç†datetimeã€Decimalç­‰ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
    """
    from decimal import Decimal
    
    def json_serializer(obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            # å°†Decimalè½¬æ¢ä¸ºfloatï¼Œä¿æŒæ•°å€¼ç²¾åº¦
            return float(obj)
        raise TypeError(f"Type {type(obj)} not serializable")
    
    return json.dumps(obj, ensure_ascii=ensure_ascii, default=json_serializer)


class DenoiseRecordManager:
    """å»å™ªè®°å½•ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        self.records_table = "ai_content_denoise_records"
        self.batch_table = "ai_denoise_batch_statistics"
        self.denoise_version = "v1.0"
    
    def generate_batch_id(self) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        return f"batch_{timestamp}_{unique_id}"
    
    def create_batch_record(
        self,
        db: Session,
        batch_id: str,
        total_work_orders: int
    ) -> bool:
        """åˆ›å»ºæ‰¹æ¬¡è®°å½•"""
        try:
            sql = f"""
            INSERT INTO {self.batch_table} (
                batch_id, total_work_orders, processed_work_orders,
                total_original_comments, total_filtered_comments, total_removed_comments,
                overall_filter_rate, processing_start_time, denoise_version, status
            ) VALUES (
                :batch_id, :total_work_orders, 0,
                0, 0, 0,
                0.00, :start_time, :version, 'PROCESSING'
            )
            """
            
            db.execute(text(sql), {
                "batch_id": batch_id,
                "total_work_orders": total_work_orders,
                "start_time": datetime.now(),
                "version": self.denoise_version
            })
            db.commit()
            
            logger.info(f"âœ… åˆ›å»ºæ‰¹æ¬¡è®°å½•: {batch_id}, å·¥å•æ•°: {total_work_orders}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ‰¹æ¬¡è®°å½•å¤±è´¥: {e}")
            db.rollback()
            return False
    
    def save_work_order_denoise_record(
        self,
        db: Session,
        work_id: int,
        batch_id: str,
        denoise_result: Dict[str, Any],
        processing_time_ms: Optional[int] = None
    ) -> bool:
        """ä¿å­˜å•ä¸ªå·¥å•çš„å»å™ªè®°å½•"""
        try:
            # è®¡ç®—è¿‡æ»¤ç‡
            original_count = denoise_result.get("original_count", 0)
            filtered_count = denoise_result.get("filtered_count", 0)
            removed_count = denoise_result.get("removed_count", 0)
            filter_rate = (removed_count / original_count * 100) if original_count > 0 else 0.0
            
            # æå–è¿‡æ»¤åŸå› å’Œè¯¦ç»†ä¿¡æ¯
            filter_statistics = denoise_result.get("filter_statistics", {})
            filter_reasons = filter_statistics.get("filter_reasons", {})
            removed_details = filter_statistics.get("removed_details", [])
            
            sql = f"""
            INSERT INTO {self.records_table} (
                work_id, batch_id, original_comment_count, filtered_comment_count,
                removed_comment_count, filter_rate, filter_reasons, removed_details,
                processing_time_ms, denoise_version
            ) VALUES (
                :work_id, :batch_id, :original_count, :filtered_count,
                :removed_count, :filter_rate, :filter_reasons, :removed_details,
                :processing_time_ms, :version
            )
            """
            
            db.execute(text(sql), {
                "work_id": work_id,
                "batch_id": batch_id,
                "original_count": original_count,
                "filtered_count": filtered_count,
                "removed_count": removed_count,
                "filter_rate": round(filter_rate, 2),
                "filter_reasons": safe_json_dumps(filter_reasons, ensure_ascii=False) if filter_reasons else None,
                "removed_details": safe_json_dumps(removed_details, ensure_ascii=False) if removed_details else None,
                "processing_time_ms": processing_time_ms,
                "version": self.denoise_version
            })
            
            logger.debug(f"ğŸ“‹ ä¿å­˜å·¥å• {work_id} å»å™ªè®°å½•: {original_count} -> {filtered_count}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å·¥å• {work_id} å»å™ªè®°å½•å¤±è´¥: {e}")
            return False
    
    def update_batch_statistics(
        self,
        db: Session,
        batch_id: str,
        statistics: Dict[str, Any],
        status: str = "COMPLETED",
        error_message: Optional[str] = None
    ) -> bool:
        """æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            processing_time_ms = statistics.get("total_processing_time_ms")
            
            sql = f"""
            UPDATE {self.batch_table}
            SET 
                processed_work_orders = :processed_orders,
                total_original_comments = :original_comments,
                total_filtered_comments = :filtered_comments,
                total_removed_comments = :removed_comments,
                overall_filter_rate = :filter_rate,
                global_filter_reasons = :filter_reasons,
                processing_end_time = :end_time,
                total_processing_time_ms = :processing_time_ms,
                status = :status,
                error_message = :error_message,
                updated_at = :updated_at
            WHERE batch_id = :batch_id
            """
            
            db.execute(text(sql), {
                "batch_id": batch_id,
                "processed_orders": statistics.get("total_work_orders", 0),
                "original_comments": statistics.get("total_original_comments", 0),
                "filtered_comments": statistics.get("total_filtered_comments", 0),
                "removed_comments": statistics.get("total_removed_comments", 0),
                "filter_rate": round(statistics.get("overall_filter_rate", 0.0), 2),
                "filter_reasons": safe_json_dumps(statistics.get("filter_reasons", {}), ensure_ascii=False),
                "end_time": datetime.now(),
                "processing_time_ms": processing_time_ms,
                "status": status,
                "error_message": error_message,
                "updated_at": datetime.now()
            })
            db.commit()
            
            logger.info(f"âœ… æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡: {batch_id}, çŠ¶æ€: {status}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡å¤±è´¥: {e}")
            db.rollback()
            return False
    
    def get_batch_statistics(
        self,
        db: Session,
        batch_id: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """è·å–æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            where_clause = "WHERE batch_id = :batch_id" if batch_id else ""
            
            sql = f"""
            SELECT 
                id, batch_id, total_work_orders, processed_work_orders,
                total_original_comments, total_filtered_comments, total_removed_comments,
                overall_filter_rate, global_filter_reasons,
                processing_start_time, processing_end_time, total_processing_time_ms,
                denoise_version, status, error_message, created_at
            FROM {self.batch_table}
            {where_clause}
            ORDER BY created_at DESC
            LIMIT :limit
            """
            
            params = {"limit": limit}
            if batch_id:
                params["batch_id"] = batch_id
            
            result = db.execute(text(sql), params)
            
            statistics = []
            for row in result:
                stat = {
                    "id": row.id,
                    "batch_id": row.batch_id,
                    "total_work_orders": row.total_work_orders,
                    "processed_work_orders": row.processed_work_orders,
                    "total_original_comments": row.total_original_comments,
                    "total_filtered_comments": row.total_filtered_comments,
                    "total_removed_comments": row.total_removed_comments,
                    "overall_filter_rate": float(row.overall_filter_rate),
                    "global_filter_reasons": json.loads(row.global_filter_reasons) if row.global_filter_reasons else {},
                    "processing_start_time": row.processing_start_time,
                    "processing_end_time": row.processing_end_time,
                    "total_processing_time_ms": row.total_processing_time_ms,
                    "denoise_version": row.denoise_version,
                    "status": row.status,
                    "error_message": row.error_message,
                    "created_at": row.created_at
                }
                statistics.append(stat)
            
            logger.info(f"ğŸ“Š è·å–åˆ° {len(statistics)} æ¡æ‰¹æ¬¡ç»Ÿè®¡è®°å½•")
            return statistics
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ‰¹æ¬¡ç»Ÿè®¡å¤±è´¥: {e}")
            return []
    
    def get_work_order_denoise_records(
        self,
        db: Session,
        work_id: Optional[int] = None,
        batch_id: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """è·å–å·¥å•å»å™ªè®°å½•"""
        try:
            where_conditions = []
            params = {"limit": limit}
            
            if work_id:
                where_conditions.append("work_id = :work_id")
                params["work_id"] = work_id
            
            if batch_id:
                where_conditions.append("batch_id = :batch_id")
                params["batch_id"] = batch_id
            
            where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
            
            sql = f"""
            SELECT 
                id, work_id, batch_id, original_comment_count, filtered_comment_count,
                removed_comment_count, filter_rate, filter_reasons, removed_details,
                processing_time_ms, denoise_version, created_at
            FROM {self.records_table}
            {where_clause}
            ORDER BY created_at DESC
            LIMIT :limit
            """
            
            result = db.execute(text(sql), params)
            
            records = []
            for row in result:
                record = {
                    "id": row.id,
                    "work_id": row.work_id,
                    "batch_id": row.batch_id,
                    "original_comment_count": row.original_comment_count,
                    "filtered_comment_count": row.filtered_comment_count,
                    "removed_comment_count": row.removed_comment_count,
                    "filter_rate": float(row.filter_rate),
                    "filter_reasons": json.loads(row.filter_reasons) if row.filter_reasons else {},
                    "removed_details": json.loads(row.removed_details) if row.removed_details else [],
                    "processing_time_ms": row.processing_time_ms,
                    "denoise_version": row.denoise_version,
                    "created_at": row.created_at
                }
                records.append(record)
            
            logger.info(f"ğŸ“‹ è·å–åˆ° {len(records)} æ¡å·¥å•å»å™ªè®°å½•")
            return records
            
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥å•å»å™ªè®°å½•å¤±è´¥: {e}")
            return []
    
    def get_denoise_summary(self, db: Session, days: int = 7) -> Dict[str, Any]:
        """è·å–å»å™ªç»Ÿè®¡æ‘˜è¦"""
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_date = datetime.now()
            start_date = end_date.replace(hour=0, minute=0, second=0, microsecond=0)
            start_date = start_date.replace(day=start_date.day - days + 1)
            
            # æ‰¹æ¬¡ç»Ÿè®¡
            batch_sql = f"""
            SELECT 
                COUNT(*) as total_batches,
                SUM(total_work_orders) as total_work_orders,
                SUM(total_original_comments) as total_original_comments,
                SUM(total_filtered_comments) as total_filtered_comments,
                SUM(total_removed_comments) as total_removed_comments,
                AVG(overall_filter_rate) as avg_filter_rate
            FROM {self.batch_table}
            WHERE created_at >= :start_date
            AND status = 'COMPLETED'
            """
            
            batch_result = db.execute(text(batch_sql), {"start_date": start_date}).fetchone()
            
            # å·¥å•è®°å½•ç»Ÿè®¡
            record_sql = f"""
            SELECT 
                COUNT(*) as total_records,
                AVG(filter_rate) as avg_work_order_filter_rate,
                MAX(filter_rate) as max_filter_rate,
                MIN(filter_rate) as min_filter_rate
            FROM {self.records_table}
            WHERE created_at >= :start_date
            """
            
            record_result = db.execute(text(record_sql), {"start_date": start_date}).fetchone()
            
            # çƒ­é—¨è¿‡æ»¤åŸå› ç»Ÿè®¡
            reasons_sql = f"""
            SELECT filter_reasons
            FROM {self.records_table}
            WHERE created_at >= :start_date
            AND filter_reasons IS NOT NULL
            """
            
            reasons_result = db.execute(text(reasons_sql), {"start_date": start_date})
            
            # èšåˆè¿‡æ»¤åŸå› 
            all_reasons = {}
            for row in reasons_result:
                if row.filter_reasons:
                    reasons = json.loads(row.filter_reasons)
                    for reason, count in reasons.items():
                        all_reasons[reason] = all_reasons.get(reason, 0) + count
            
            # æ’åºè·å–å‰10ä¸ªçƒ­é—¨åŸå› 
            top_reasons = sorted(all_reasons.items(), key=lambda x: x[1], reverse=True)[:10]
            
            summary = {
                "time_range": {
                    "start_date": start_date.strftime("%Y-%m-%d"),
                    "end_date": end_date.strftime("%Y-%m-%d"),
                    "days": days
                },
                "batch_statistics": {
                    "total_batches": batch_result.total_batches or 0,
                    "total_work_orders": batch_result.total_work_orders or 0,
                    "total_original_comments": batch_result.total_original_comments or 0,
                    "total_filtered_comments": batch_result.total_filtered_comments or 0,
                    "total_removed_comments": batch_result.total_removed_comments or 0,
                    "avg_filter_rate": round(float(batch_result.avg_filter_rate or 0), 2)
                },
                "record_statistics": {
                    "total_records": record_result.total_records or 0,
                    "avg_work_order_filter_rate": round(float(record_result.avg_work_order_filter_rate or 0), 2),
                    "max_filter_rate": round(float(record_result.max_filter_rate or 0), 2),
                    "min_filter_rate": round(float(record_result.min_filter_rate or 0), 2)
                },
                "top_filter_reasons": [{"reason": reason, "count": count} for reason, count in top_reasons]
            }
            
            logger.info(f"ğŸ“Š ç”Ÿæˆå»å™ªç»Ÿè®¡æ‘˜è¦: {days}å¤©å†… {summary['batch_statistics']['total_batches']} ä¸ªæ‰¹æ¬¡")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ è·å–å»å™ªç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
            return {
                "error": str(e),
                "time_range": {"days": days},
                "batch_statistics": {},
                "record_statistics": {},
                "top_filter_reasons": []
            }


# å…¨å±€å»å™ªè®°å½•ç®¡ç†å™¨å®ä¾‹
denoise_record_manager = DenoiseRecordManager()
